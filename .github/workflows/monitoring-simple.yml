name: Monitoring and Alerting

on:
  schedule:
    # Run monitoring checks every hour  
    - cron: '0 * * * *'
  
  workflow_dispatch:
    inputs:
      check_type:
        description: 'Type of monitoring check to run'
        required: true
        default: 'all'
        type: choice
        options:
        - all
        - drift
        - performance
        - health
        - security

  # Triggered by external monitoring systems
  repository_dispatch:
    types: [alert-triggered, service-down, high-drift]

env:
  SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
  ALERT_EMAIL: ${{ secrets.ALERT_EMAIL }}

jobs:
  # ================================
  # SYSTEM HEALTH MONITORING
  # ================================
  health-monitoring:
    name: System Health Check
    runs-on: ubuntu-latest
    if: github.event.inputs.check_type == 'all' || github.event.inputs.check_type == 'health' || github.event_name != 'workflow_dispatch'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Check API service health
      id: api_health
      run: |
        echo "Checking API service health..."
        
        # In production, this would check actual endpoints
        api_status="healthy"
        response_time="120ms"
        uptime="99.8%"
        
        echo "API Status: $api_status"
        echo "Response Time: $response_time"  
        echo "Uptime: $uptime"
        
        echo "status=$api_status" >> $GITHUB_OUTPUT
        echo "response_time=$response_time" >> $GITHUB_OUTPUT
        echo "uptime=$uptime" >> $GITHUB_OUTPUT

    - name: Check container resource usage
      id: resource_check
      run: |
        echo "Checking container resource usage..."
        
        # Simulate resource monitoring
        cpu_usage="45%"
        memory_usage="60%"
        disk_usage="75%"
        
        echo "CPU Usage: $cpu_usage"
        echo "Memory Usage: $memory_usage"  
        echo "Disk Usage: $disk_usage"
        
        echo "cpu=$cpu_usage" >> $GITHUB_OUTPUT
        echo "memory=$memory_usage" >> $GITHUB_OUTPUT
        echo "disk=$disk_usage" >> $GITHUB_OUTPUT

  # ================================
  # DRIFT MONITORING
  # ================================
  drift-monitoring:
    name: Data Drift Monitoring
    runs-on: ubuntu-latest
    if: github.event.inputs.check_type == 'all' || github.event.inputs.check_type == 'drift' || github.event_name != 'workflow_dispatch'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: 3.9
        cache: 'pip'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pandas numpy scipy

    - name: Analyze drift patterns
      id: drift_analysis
      continue-on-error: true
      run: |
        echo "Analyzing data drift patterns..."
        
        python -c "
        import glob
        import pandas as pd
        import json
        from datetime import datetime
        
        # Analyze recent drift reports
        drift_files = sorted(glob.glob('drift_reports/*.csv'))
        recent_files = drift_files[-10:] if len(drift_files) > 10 else drift_files
        
        if not recent_files:
            print('No drift reports found')
            print('status=no_data' >> open('drift_status.txt', 'w'))
            exit(0)
        
        total_features = 0
        drifted_features = 0
        
        for file in recent_files:
            try:
                df = pd.read_csv(file)
                if 'drift_flag' in df.columns:
                    total_features += len(df)
                    drifted_features += df['drift_flag'].sum()
            except Exception as e:
                print(f'Error reading {file}: {e}')
                continue
        
        if total_features == 0:
            print('No valid drift data found')
            print('status=no_data' >> open('drift_status.txt', 'w'))
            exit(0)
        
        drift_percentage = (drifted_features / total_features) * 100
        
        print(f'Drift Analysis Results:')
        print(f'  Total features analyzed: {total_features}')
        print(f'  Features with drift: {drifted_features} ({drift_percentage:.1f}%)')
        
        # Determine alert level
        if drift_percentage > 30:
            status = 'critical'
        elif drift_percentage > 15:
            status = 'warning'
        else:
            status = 'normal'
        
        print(f'  Alert level: {status}')
        
        # Save outputs
        with open('drift_status.txt', 'w') as f:
            f.write(f'status={status}\\n')
            f.write(f'drift_percentage={drift_percentage:.1f}\\n')
            f.write(f'drifted_features={drifted_features}\\n')
            f.write(f'total_features={total_features}\\n')
        
        print('Drift analysis completed')
        " || echo "Drift analysis completed with warnings"

  # ================================
  # PERFORMANCE MONITORING
  # ================================  
  performance-monitoring:
    name: Model Performance Monitoring
    runs-on: ubuntu-latest
    if: github.event.inputs.check_type == 'all' || github.event.inputs.check_type == 'performance' || github.event_name != 'workflow_dispatch'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Analyze model performance trends
      id: performance_analysis
      continue-on-error: true
      run: |
        echo "Analyzing model performance trends..."
        
        python3 -c "
        import json
        import os
        from datetime import datetime
        
        if not os.path.exists('models/metrics_history.json'):
            print('No metrics history found')
            exit(0)
        
        try:
            with open('models/metrics_history.json', 'r') as f:
                history = json.load(f)
            
            if not history or len(history) < 2:
                print('Insufficient data for trend analysis')
                exit(0)
            
            # Analyze recent performance
            recent = history[-5:] if len(history) >= 5 else history
            
            aucs = [r.get('metrics', {}).get('auc', 0) for r in recent if r.get('metrics', {}).get('auc')]
            
            if aucs:
                latest_auc = aucs[-1]
                avg_auc = sum(aucs) / len(aucs)
                
                print(f'Performance Analysis:')
                print(f'  Latest AUC: {latest_auc:.4f}')
                print(f'  Average AUC: {avg_auc:.4f}')
                
                if latest_auc < 0.7:
                    status = 'critical'
                elif latest_auc > avg_auc:
                    status = 'improving'
                else:
                    status = 'stable'
                
                print(f'  Status: {status}')
            else:
                print('No valid AUC metrics found')
        except Exception as e:
            print(f'Error analyzing performance: {e}')
        " || echo "Performance analysis completed with warnings"

  # ================================
  # SECURITY MONITORING
  # ================================
  security-monitoring:
    name: Security Monitoring
    runs-on: ubuntu-latest
    if: github.event.inputs.check_type == 'all' || github.event.inputs.check_type == 'security' || github.event_name != 'workflow_dispatch'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Basic security check
      continue-on-error: true
      run: |
        echo "Running basic security checks..."
        
        # Check for potential secrets
        if grep -r -i -E "(password|token|key|secret)" . --exclude-dir=.git --exclude-dir=.github || true; then
          echo "Potential sensitive data found - please review"
        else
          echo "No obvious sensitive data detected"
        fi
        
        echo "Security check completed"

  # ================================
  # SEND SUMMARY REPORT
  # ================================
  send-summary:
    name: Send Summary Report
    runs-on: ubuntu-latest
    needs: [health-monitoring, drift-monitoring, performance-monitoring, security-monitoring]
    if: always()
    
    steps:
    - name: Create summary
      run: |
        echo "Monitoring Summary Report"
        echo "========================="
        echo "Health Monitoring: ${{ needs.health-monitoring.result }}"
        echo "Drift Monitoring: ${{ needs.drift-monitoring.result }}"
        echo "Performance Monitoring: ${{ needs.performance-monitoring.result }}"
        echo "Security Monitoring: ${{ needs.security-monitoring.result }}"
        echo ""
        echo "Report generated at: $(date)"